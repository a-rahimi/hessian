{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tutorial: Block Partitioned Matrices\n",
                "\n",
                "This tutorial introduces the `block_partitioned_matrices` library, which provides a framework for working with matrices that have a hierarchical block structure. This structure allows for efficient operations like inversion and solving linear systems by exploiting the sparsity and structure of the matrices.\n",
                "\n",
                "## 1. Introduction and Setup\n",
                "\n",
                "The library is located in `src/block_partitioned_matrices.py`. Since this notebook is also in `src/`, we can import it directly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import block_partitioned_matrices as bpm\n",
                "from block_partitioned_matrices import (\n",
                "    Tensor,\n",
                "    Identity,\n",
                "    Zero,\n",
                "    Vertical,\n",
                "    Generic,\n",
                "    Diagonal,\n",
                "    Symmetric2x2,\n",
                "    Tridiagonal,\n",
                "    LowerBiDiagonal,\n",
                ")\n",
                "\n",
                "\n",
                "# Helper function to create column vectors easily\n",
                "def col(*args):\n",
                "    return torch.tensor(args)[:, None]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Basic Components\n",
                "\n",
                "The library builds upon a base `Matrix` class. The fundamental building blocks are:\n",
                "\n",
                "*   `Tensor`: A wrapper around `torch.Tensor`.\n",
                "*   `Identity`: Represents an identity matrix (implicitly).\n",
                "*   `Zero`: Represents a zero matrix (implicitly).\n",
                "*   `Vertical`: Represents a column vector of blocks.\n",
                "*   `Diagonal`: Represents a block-diagonal matrix."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Wrappers and Placeholders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Wrapped Tensor:\n",
                        "Tensor([[1., 2.],\n",
                        "        [3., 4.]])\n",
                        "\n",
                        "Identity + Zero (converted to dense tensor):\n",
                        "tensor([[1., 0.],\n",
                        "        [0., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "# Wrap a standard PyTorch tensor\n",
                "t = Tensor(torch.tensor([[1.0, 2.0], [3.0, 4.0]]))\n",
                "print(\"Wrapped Tensor:\")\n",
                "print(t.to_tensor())\n",
                "\n",
                "# Identity and Zero matrices don't store full data\n",
                "I = Identity(2)  # 2x2 Identity\n",
                "Z = Zero((2, 2))  # 2x2 Zero\n",
                "\n",
                "print(\"\\nIdentity + Zero (converted to dense tensor):\")\n",
                "print((I + Z).to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Vertical (Block Vectors)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vertical Vector properties:\n",
                        "Shape: (2, 1)\n",
                        "Number of blocks: 2\n",
                        "Dense representation:\n",
                        "Tensor([[1.],\n",
                        "        [2.],\n",
                        "        [3.],\n",
                        "        [4.],\n",
                        "        [5.]])\n"
                    ]
                }
            ],
            "source": [
                "# Construct a vertical vector from two smaller vectors\n",
                "V = Vertical([col(1.0, 2.0), col(3.0, 4.0, 5.0)])\n",
                "\n",
                "print(\"Vertical Vector properties:\")\n",
                "print(f\"Shape: {V.shape}\")\n",
                "print(f\"Number of blocks: {V.num_blocks()}\")\n",
                "print(\"Dense representation:\")\n",
                "print(V.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Block Diagonal Matrices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Block Diagonal Matrix:\n",
                        "Tensor([[1., 0., 0., 0., 0.],\n",
                        "        [0., 1., 0., 0., 0.],\n",
                        "        [0., 0., 1., 1., 1.],\n",
                        "        [0., 0., 1., 1., 1.],\n",
                        "        [0., 0., 1., 1., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "# Create a block diagonal matrix from two blocks\n",
                "D = Diagonal([torch.eye(2), torch.ones(3, 3)])\n",
                "\n",
                "print(\"\\nBlock Diagonal Matrix:\")\n",
                "print(D.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Core Operations\n",
                "\n",
                "The library supports standard linear algebra operations while maintaining the block structure where possible.\n",
                "\n",
                "*   **Arithmetic**: `+`, `-`\n",
                "*   **Multiplication**: `@` (matmul)\n",
                "*   **Inversion**: `.invert()`\n",
                "*   **Solving**: `.solve(rhs)`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Arithmetic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sum of two diagonal matrices:\n",
                        "Tensor([[3., 0., 0., 0., 0.],\n",
                        "        [0., 3., 0., 0., 0.],\n",
                        "        [0., 0., 3., 1., 1.],\n",
                        "        [0., 0., 1., 3., 1.],\n",
                        "        [0., 0., 1., 1., 3.]])\n"
                    ]
                }
            ],
            "source": [
                "D2 = Diagonal([2 * torch.eye(2), 2 * torch.eye(3)])\n",
                "D_sum = D + D2\n",
                "print(\"Sum of two diagonal matrices:\")\n",
                "print(D_sum.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Matrix-Vector Multiplication\n",
                "\n",
                "Multiply Diagonal matrix D by Vertical vector V.\n",
                "\n",
                "Dimensions: D is (5x5), V is (5x1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Matrix-Vector Multiplication (D @ V):\n",
                        "Tensor([[ 1.],\n",
                        "        [ 2.],\n",
                        "        [12.],\n",
                        "        [12.],\n",
                        "        [12.]])\n"
                    ]
                }
            ],
            "source": [
                "result = D @ V\n",
                "print(\"Matrix-Vector Multiplication (D @ V):\")\n",
                "print(result.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Inversion\n",
                "\n",
                "Invert a diagonal matrix (inverts each block individually)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Inverse of D2:\n",
                        "Tensor([[0.5000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
                        "        [0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
                        "        [0.0000, 0.0000, 0.5000, 0.0000, 0.0000],\n",
                        "        [0.0000, 0.0000, 0.0000, 0.5000, 0.0000],\n",
                        "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5000]])\n",
                        "\n",
                        "D2 @ D2_inv (Top-left block):\n",
                        "Tensor([[1., 0.],\n",
                        "        [0., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "D_inv = D2.invert()\n",
                "print(\"Inverse of D2:\")\n",
                "print(D_inv.to_tensor())\n",
                "\n",
                "# Verify inversion\n",
                "should_be_identity = D2 @ D_inv\n",
                "print(\"\\nD2 @ D2_inv (Top-left block):\")\n",
                "print(should_be_identity.flat[0].to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4 Solving Linear Systems\n",
                "\n",
                "Solve $D_2 x = V$. Since $D_2$ is diagonal, this solves block-wise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Solution x to D2 @ x = V:\n",
                        "Tensor([[0.5000],\n",
                        "        [1.0000],\n",
                        "        [1.5000],\n",
                        "        [2.0000],\n",
                        "        [2.5000]])\n",
                        "Residual norm: 0.0\n"
                    ]
                }
            ],
            "source": [
                "x = D2.solve(V)\n",
                "\n",
                "print(\"Solution x to D2 @ x = V:\")\n",
                "print(x.to_tensor())\n",
                "\n",
                "# Verify solution\n",
                "residual = (D2 @ x - V).to_tensor()\n",
                "print(f\"Residual norm: {residual.norm().item()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.5 Generic Matrices\n",
                "\n",
                "A `Generic` matrix is a grid of blocks, similar to how one might partition a matrix on paper. This is useful for constructing arbitrary block structures."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generic 2x2 Block Matrix:\n",
                        "Tensor([[1., 1., 0., 0., 0.],\n",
                        "        [1., 1., 0., 0., 0.],\n",
                        "        [0., 0., 1., 0., 0.],\n",
                        "        [0., 0., 0., 1., 0.],\n",
                        "        [0., 0., 0., 0., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "G = Generic(\n",
                "    [\n",
                "        [torch.ones(2, 2), torch.zeros(2, 3)],\n",
                "        [torch.zeros(3, 2), torch.eye(3)],\n",
                "    ]\n",
                ")\n",
                "print(\"Generic 2x2 Block Matrix:\")\n",
                "print(G.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.6 Hierarchical (Nested) Structures\n",
                "\n",
                "The true power of the library comes from nesting structures. For instance, the blocks of a `Generic` matrix can themselves be `Diagonal` matrices, or any other `Matrix` subclass."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Nested Block Matrix:\n",
                        "Tensor([[1., 0., 0., 0., 0., 0.],\n",
                        "        [0., 1., 0., 0., 0., 0.],\n",
                        "        [0., 0., 1., 0., 0., 0.],\n",
                        "        [0., 0., 0., 1., 0., 0.],\n",
                        "        [0., 0., 0., 0., 1., 1.],\n",
                        "        [0., 0., 0., 0., 1., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "Nested = Generic(\n",
                "    [\n",
                "        [Diagonal([torch.eye(2), torch.eye(2)]), Zero((4, 2))],\n",
                "        [Zero((2, 4)), Tensor(torch.ones(2, 2))],\n",
                "    ]\n",
                ")\n",
                "print(\"Nested Block Matrix:\")\n",
                "print(Nested.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Specialized Structures\n",
                "\n",
                "Beyond just stacking blocks vertically, horizontally, and diagonally, the\n",
                "library offers ways to compactly store symemtric and banded-diagonal matrices.\n",
                "\n",
                "### 4.1 Symmetric 2x2 Block Matrix\n",
                "\n",
                "Represents a matrix of the form:\n",
                "$$\n",
                "\\begin{pmatrix}\n",
                "A_{11} & A_{12} \\\\\n",
                "A_{12}^T & A_{22}\n",
                "\\end{pmatrix}\n",
                "$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Symmetric 2x2 Matrix:\n",
                        "Tensor([[1.0000, 0.0000, 0.1000, 0.1000],\n",
                        "        [0.0000, 1.0000, 0.1000, 0.1000],\n",
                        "        [0.1000, 0.1000, 4.0000, 0.0000],\n",
                        "        [0.1000, 0.1000, 0.0000, 4.0000]])\n",
                        "Inverse of Symmetric 2x2:\n",
                        "Tensor([[ 1.0051,  0.0051, -0.0253, -0.0253],\n",
                        "        [ 0.0051,  1.0051, -0.0253, -0.0253],\n",
                        "        [-0.0253, -0.0253,  0.2513,  0.0013],\n",
                        "        [-0.0253, -0.0253,  0.0013,  0.2513]])\n"
                    ]
                }
            ],
            "source": [
                "S = Symmetric2x2(torch.eye(2), 0.1 * torch.ones(2, 2), torch.eye(2) * 4)\n",
                "print(\"Symmetric 2x2 Matrix:\")\n",
                "print(S.to_tensor())\n",
                "\n",
                "# Confirm the matrix can be inverted.\n",
                "torch.linalg.inv(S.to_tensor())\n",
                "\n",
                "# Inversion uses Schur complement internally\n",
                "S_inv = S.invert()\n",
                "print(\"Inverse of Symmetric 2x2:\")\n",
                "print(S_inv.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Tridiagonal and Bi-diagonal Matrices\n",
                "\n",
                "Structures like `LowerBiDiagonal`, `UpperBiDiagonal`, and `Tridiagonal` allow for solving systems using forward/backward substitution or LDU decompositions, which is $O(N)$ in the number of blocks rather than $O(N^3)$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Lower Bi-Diagonal Matrix:\n",
                        "Tensor([[1., 0., 0., 0.],\n",
                        "        [0., 1., 0., 0.],\n",
                        "        [1., 1., 1., 0.],\n",
                        "        [1., 1., 0., 1.]])\n",
                        "\n",
                        "Solution to L_mat @ x = rhs:\n",
                        "Tensor([[1.],\n",
                        "        [1.],\n",
                        "        [0.],\n",
                        "        [0.]])\n"
                    ]
                }
            ],
            "source": [
                "# Construct a Lower Bi-Diagonal Matrix\n",
                "# [ D1  0 ]\n",
                "# [ L1  D2]\n",
                "L_mat = LowerBiDiagonal(\n",
                "    diagonal_blocks=[torch.eye(2), torch.eye(2)], lower_blocks=[torch.ones(2, 2)]\n",
                ")\n",
                "print(\"Lower Bi-Diagonal Matrix:\")\n",
                "print(L_mat.to_tensor())\n",
                "\n",
                "# Solve using forward substitution (implicitly)\n",
                "rhs = Vertical([col(1.0, 1.0), col(2.0, 2.0)])\n",
                "sol_L = L_mat.solve(rhs)\n",
                "print(\"\\nSolution to L_mat @ x = rhs:\")\n",
                "print(sol_L.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Decompositions\n",
                "\n",
                "The library implements decompositions like LDU (Lower-Diagonal-Upper) for `Tridiagonal` matrices to facilitate efficient solving and inversion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tridiagonal Matrix:\n",
                        "Tensor([[2.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000],\n",
                        "        [0.0000, 2.0000, 0.5000, 0.5000, 0.0000, 0.0000],\n",
                        "        [0.5000, 0.5000, 2.0000, 0.0000, 0.5000, 0.5000],\n",
                        "        [0.5000, 0.5000, 0.0000, 2.0000, 0.5000, 0.5000],\n",
                        "        [0.0000, 0.0000, 0.5000, 0.5000, 2.0000, 0.0000],\n",
                        "        [0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 2.0000]])\n",
                        "\n",
                        "Decomposed components:\n",
                        "L type: <class 'block_partitioned_matrices.IdentityWithLowerDiagonal'>\n",
                        "D type: <class 'block_partitioned_matrices.Diagonal'>\n",
                        "U type: <class 'block_partitioned_matrices.IdentityWithUpperDiagonal'>\n",
                        "\n",
                        "Difference between tri @ v and L @ D @ U @ v:\n",
                        "0.0\n"
                    ]
                }
            ],
            "source": [
                "# Create a Tridiagonal Matrix\n",
                "tri = Tridiagonal(\n",
                "    [torch.eye(2) * 2, torch.eye(2) * 2, torch.eye(2) * 2],\n",
                "    lower_blocks=[0.5 * torch.ones(2, 2), 0.5 * torch.ones(2, 2)],\n",
                "    upper_blocks=[0.5 * torch.ones(2, 2), 0.5 * torch.ones(2, 2)],\n",
                ")\n",
                "print(\"Tridiagonal Matrix:\")\n",
                "print(tri.to_tensor())\n",
                "\n",
                "# Perform LDU Decomposition\n",
                "L, D, U = tri.LDU_decomposition()\n",
                "\n",
                "print(\"\\nDecomposed components:\")\n",
                "print(f\"L type: {type(L)}\")\n",
                "print(f\"D type: {type(D)}\")\n",
                "print(f\"U type: {type(U)}\")\n",
                "\n",
                "# Verify correctness by applying to a vector\n",
                "v = Vertical([col(1.0, 1.0), col(2.0, 2.0), col(3.0, 3.0)])\n",
                "\n",
                "# Apply original matrix\n",
                "tri_v = tri @ v\n",
                "\n",
                "# Apply decomposed factors: L @ (D @ (U @ v))\n",
                "LDU_v = L @ (D @ (U @ v))\n",
                "\n",
                "print(\"\\nDifference between tri @ v and L @ D @ U @ v:\")\n",
                "print((LDU_v - tri_v).to_tensor().norm().item())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
