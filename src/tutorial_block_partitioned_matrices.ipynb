{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tutorial: Block Partitioned Matrices\n",
                "\n",
                "This tutorial introduces the `block_partitioned_matrices`, a library of\n",
                "operations on hierarchically nested structured matrices.  The library builds\n",
                "upon a base `Matrix` class. Here are some examples of its derived class:\n",
                "\n",
                "*   `Tensor`: A wrapper around `torch.Tensor`.\n",
                "*   `Identity`: Represents an identity matrix (implicitly).\n",
                "*   `Zero`: Represents a zero matrix (implicitly).\n",
                "*   `Vertical`: Represents a column vector of blocks.\n",
                "*   `Diagonal`: Represents a block-diagonal matrix.\n",
                "* ...\n",
                "\n",
                "What sets this library apart from other matrix libraries is that matrices can be\n",
                "nested within each other. For example, tensors can be stacked diagonally into a\n",
                "`Diagonal` matrix of `Tensor` matrices. These can in turn be stacked vertically\n",
                "into a `Vertical` matrix.\n",
                "\n",
                "Here is a full list of the matrix classes:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Matrix\n",
                        "├── Tensor (also torch.Tensor)\n",
                        "├── Identity\n",
                        "│   └── ScaledIdentity\n",
                        "├── Zero\n",
                        "└── Ragged\n",
                        "    ├── Generic\n",
                        "    │   ├── Generic3x3\n",
                        "    │   ├── Vertical\n",
                        "    │   └── Horizontal\n",
                        "    ├── Symmetric2x2\n",
                        "    └── Tridiagonal\n",
                        "        ├── SymmetricTriDiagonal\n",
                        "        ├── LowerBiDiagonal\n",
                        "        │   ├── IdentityWithLowerDiagonal\n",
                        "        │   └── LowerDiagonal\n",
                        "        ├── UpperBiDiagonal\n",
                        "        │   ├── IdentityWithUpperDiagonal\n",
                        "        │   └── UpperDiagonal\n",
                        "        └── Diagonal\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "import block_partitioned_matrices as bpm\n",
                "# Print the last paragraph of the module docstring. It's automatically\n",
                "# generated.\n",
                "print(bpm.__doc__.split(\"\\n\\n\")[-1])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Introduction and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from block_partitioned_matrices import (\n",
                "    Tensor,\n",
                "    Identity,\n",
                "    Zero,\n",
                "    Vertical,\n",
                "    Generic,\n",
                "    Diagonal,\n",
                "    Symmetric2x2,\n",
                "    Tridiagonal,\n",
                "    LowerBiDiagonal,\n",
                ")\n",
                "\n",
                "\n",
                "# Helper function to create column vectors easily\n",
                "def col(*args):\n",
                "    return torch.tensor(args)[:, None]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Basic Components"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Placeholder matrices like Zero, Identity, etc lets us represent certain matrices\n",
                "without storing their content:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Wrapped Tensor:\n",
                        "tensor([[1., 2.],\n",
                        "        [3., 4.]])\n",
                        "\n",
                        "Identity + Zero (converted to dense tensor):\n",
                        "tensor([[1., 0.],\n",
                        "        [0., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "# Wrap a standard PyTorch tensor\n",
                "t = Tensor(torch.tensor([[1.0, 2.0], [3.0, 4.0]]))\n",
                "print(\"Wrapped Tensor:\")\n",
                "print(t.to_tensor())\n",
                "\n",
                "# Identity and Zero matrices don't store full data\n",
                "I = Identity(2)  # 2x2 Identity\n",
                "Z = Zero((2, 2))  # 2x2 Zero\n",
                "\n",
                "print(\"\\nIdentity + Zero (converted to dense tensor):\")\n",
                "print((I + Z).to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here is a typical way to construct a matrix (in this case, two column vectors stacked on top of each other):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vertical Vector properties:\n",
                        "Shape: (2, 1)\n",
                        "Number of blocks: 2\n",
                        "Dense representation:\n",
                        "tensor([[1.],\n",
                        "        [2.],\n",
                        "        [3.],\n",
                        "        [4.],\n",
                        "        [5.]])\n"
                    ]
                }
            ],
            "source": [
                "# Construct a vertical vector from two smaller vectors\n",
                "V = Vertical([col(1.0, 2.0), col(3.0, 4.0, 5.0)])\n",
                "\n",
                "print(\"Vertical Vector properties:\")\n",
                "print(f\"Shape: {V.shape}\")\n",
                "print(f\"Number of blocks: {V.num_blocks()}\")\n",
                "print(\"Dense representation:\")\n",
                "print(V.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Similarly, we can stack matrices into a 2x2 block diagonal matrix:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Block Diagonal Matrix:\n",
                        "tensor([[1., 0., 0., 0., 0.],\n",
                        "        [0., 1., 0., 0., 0.],\n",
                        "        [0., 0., 1., 1., 1.],\n",
                        "        [0., 0., 1., 1., 1.],\n",
                        "        [0., 0., 1., 1., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "# Create a block diagonal matrix from two blocks\n",
                "D = Diagonal([torch.eye(2), torch.ones(3, 3)])\n",
                "\n",
                "print(\"\\nBlock Diagonal Matrix:\")\n",
                "print(D.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The library supports standard linear algebra operations. These take advantage of\n",
                "the structure of the matrices and return structured matrices as results:\n",
                "\n",
                "*   **Arithmetic**: `+`, `-`\n",
                "*   **Multiplication**: `@` (matmul)\n",
                "*   **Inversion**: `.invert()`\n",
                "*   **Solving**: `.solve(rhs)`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sum of two diagonal matrices:\n",
                        "tensor([[3., 0., 0., 0., 0.],\n",
                        "        [0., 3., 0., 0., 0.],\n",
                        "        [0., 0., 3., 1., 1.],\n",
                        "        [0., 0., 1., 3., 1.],\n",
                        "        [0., 0., 1., 1., 3.]])\n"
                    ]
                }
            ],
            "source": [
                "D2 = Diagonal([2 * torch.eye(2), 2 * torch.eye(3)])\n",
                "D_sum = D + D2\n",
                "print(\"Sum of two diagonal matrices:\")\n",
                "print(D_sum.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Multiply Diagonal matrix D by Vertical vector V."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Matrix-Vector Multiplication (D @ V):\n",
                        "tensor([[ 1.],\n",
                        "        [ 2.],\n",
                        "        [12.],\n",
                        "        [12.],\n",
                        "        [12.]])\n"
                    ]
                }
            ],
            "source": [
                "result = D @ V\n",
                "print(\"Matrix-Vector Multiplication (D @ V):\")\n",
                "print(result.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Invert a diagonal matrix (inverts each block individually)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Inverse of D2:\n",
                        "tensor([[0.5000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
                        "        [0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
                        "        [0.0000, 0.0000, 0.5000, 0.0000, 0.0000],\n",
                        "        [0.0000, 0.0000, 0.0000, 0.5000, 0.0000],\n",
                        "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5000]])\n",
                        "\n",
                        "D2 @ D2_inv (Top-left block):\n",
                        "tensor([[1., 0.],\n",
                        "        [0., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "D_inv = D2.invert()\n",
                "print(\"Inverse of D2:\")\n",
                "print(D_inv.to_tensor())\n",
                "\n",
                "# Verify inversion\n",
                "should_be_identity = D2 @ D_inv\n",
                "print(\"\\nD2 @ D2_inv (Top-left block):\")\n",
                "print(should_be_identity.flat[0].to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Solve $D_2 x = V$. Since $D_2$ is diagonal, this solves block-wise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Solution x to D2 @ x = V:\n",
                        "tensor([[0.5000],\n",
                        "        [1.0000],\n",
                        "        [1.5000],\n",
                        "        [2.0000],\n",
                        "        [2.5000]])\n",
                        "Residual norm: 0.0\n"
                    ]
                }
            ],
            "source": [
                "x = D2.solve(V)\n",
                "\n",
                "print(\"Solution x to D2 @ x = V:\")\n",
                "print(x.to_tensor())\n",
                "\n",
                "# Verify solution\n",
                "residual = (D2 @ x - V).to_tensor()\n",
                "print(f\"Residual norm: {residual.norm().item()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Nesting matrices\n",
                "\n",
                "A `Generic` matrix is a grid of blocks, similar to how one might partition a\n",
                "rectangular matrix on paper. Here is a 2x2 block matrix, each of whose blocks are torch Tensors:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generic 2x2 Block Matrix:\n",
                        "tensor([[1., 1., 0., 0., 0.],\n",
                        "        [1., 1., 0., 0., 0.],\n",
                        "        [0., 0., 1., 0., 0.],\n",
                        "        [0., 0., 0., 1., 0.],\n",
                        "        [0., 0., 0., 0., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "G = Generic(\n",
                "    [\n",
                "        [torch.ones(2, 2), torch.zeros(2, 3)],\n",
                "        [torch.zeros(3, 2), torch.eye(3)],\n",
                "    ]\n",
                ")\n",
                "print(\"Generic 2x2 Block Matrix:\")\n",
                "print(G.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The power of the library comes from nesting matrices. For example, the blocks of\n",
                "a `Generic` matrix can be `Diagonal` matrices, or any other `Matrix` subclass:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Nested Block Matrix:\n",
                        "tensor([[1., 0., 0., 0., 0., 0.],\n",
                        "        [0., 1., 0., 0., 0., 0.],\n",
                        "        [0., 0., 1., 0., 0., 0.],\n",
                        "        [0., 0., 0., 1., 0., 0.],\n",
                        "        [0., 0., 0., 0., 1., 1.],\n",
                        "        [0., 0., 0., 0., 1., 1.]])\n"
                    ]
                }
            ],
            "source": [
                "Nested = Generic(\n",
                "    [\n",
                "        [Diagonal([torch.eye(2), torch.eye(2)]), Zero((4, 2))],\n",
                "        [Zero((2, 4)), Tensor(torch.ones(2, 2))],\n",
                "    ]\n",
                ")\n",
                "print(\"Nested Block Matrix:\")\n",
                "print(Nested.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Specialized Structures\n",
                "\n",
                "Beyond just stacking blocks vertically, horizontally, and diagonally, the\n",
                "library offers ways to compactly store symmetric and banded-diagonal matrices.\n",
                "\n",
                "### 3.1 Symmetric 2x2 Block Matrix\n",
                "\n",
                "Represents a matrix of the form:\n",
                "$$\n",
                "\\begin{pmatrix}\n",
                "A_{11} & A_{12} \\\\\n",
                "A_{12}^T & A_{22}\n",
                "\\end{pmatrix}\n",
                "$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Symmetric 2x2 Matrix:\n",
                        "tensor([[1.0000, 0.0000, 0.1000, 0.1000],\n",
                        "        [0.0000, 1.0000, 0.1000, 0.1000],\n",
                        "        [0.1000, 0.1000, 4.0000, 0.0000],\n",
                        "        [0.1000, 0.1000, 0.0000, 4.0000]])\n",
                        "Inverse of Symmetric 2x2:\n",
                        "tensor([[ 1.0051,  0.0051, -0.0253, -0.0253],\n",
                        "        [ 0.0051,  1.0051, -0.0253, -0.0253],\n",
                        "        [-0.0253, -0.0253,  0.2513,  0.0013],\n",
                        "        [-0.0253, -0.0253,  0.0013,  0.2513]])\n"
                    ]
                }
            ],
            "source": [
                "S = Symmetric2x2(torch.eye(2), 0.1 * torch.ones(2, 2), torch.eye(2) * 4)\n",
                "print(\"Symmetric 2x2 Matrix:\")\n",
                "print(S.to_tensor())\n",
                "\n",
                "# Confirm the matrix can be inverted.\n",
                "torch.linalg.inv(S.to_tensor())\n",
                "\n",
                "# Inversion uses Schur complement internally\n",
                "S_inv = S.invert()\n",
                "print(\"Inverse of Symmetric 2x2:\")\n",
                "print(S_inv.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Tridiagonal and Bi-diagonal Matrices\n",
                "\n",
                "Structures like `LowerBiDiagonal`, `UpperBiDiagonal`, and `Tridiagonal` allow for solving systems using forward/backward substitution or LDU decompositions, which is $O(N)$ in the number of blocks rather than $O(N^3)$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Lower Bi-Diagonal Matrix:\n",
                        "tensor([[1., 0., 0., 0.],\n",
                        "        [0., 1., 0., 0.],\n",
                        "        [1., 1., 1., 0.],\n",
                        "        [1., 1., 0., 1.]])\n",
                        "\n",
                        "Solution to L_mat @ x = rhs:\n",
                        "tensor([[1.],\n",
                        "        [1.],\n",
                        "        [0.],\n",
                        "        [0.]])\n"
                    ]
                }
            ],
            "source": [
                "# Construct a Lower Bi-Diagonal Matrix\n",
                "# [ D1  0 ]\n",
                "# [ L1  D2]\n",
                "L_mat = LowerBiDiagonal(\n",
                "    diagonal_blocks=[torch.eye(2), torch.eye(2)], lower_blocks=[torch.ones(2, 2)]\n",
                ")\n",
                "print(\"Lower Bi-Diagonal Matrix:\")\n",
                "print(L_mat.to_tensor())\n",
                "\n",
                "# Solve using forward substitution (implicitly)\n",
                "rhs = Vertical([col(1.0, 1.0), col(2.0, 2.0)])\n",
                "sol_L = L_mat.solve(rhs)\n",
                "print(\"\\nSolution to L_mat @ x = rhs:\")\n",
                "print(sol_L.to_tensor())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Matrix Decomposition\n",
                "\n",
                "The library implements some basic factorization algorithms. These algorithms can handle nested matrices.\n",
                "\n",
                "For example, we can decompose a `Tridiagonal` matrix of blocks into LDU (Lower-Diagonal-Upper). This lets use solve linear systems:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tridiagonal Matrix:\n",
                        "tensor([[2.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000],\n",
                        "        [0.0000, 2.0000, 0.5000, 0.5000, 0.0000, 0.0000],\n",
                        "        [0.5000, 0.5000, 2.0000, 0.0000, 0.5000, 0.5000],\n",
                        "        [0.5000, 0.5000, 0.0000, 2.0000, 0.5000, 0.5000],\n",
                        "        [0.0000, 0.0000, 0.5000, 0.5000, 2.0000, 0.0000],\n",
                        "        [0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 2.0000]])\n",
                        "\n",
                        "Decomposed components:\n",
                        "L type: <class 'block_partitioned_matrices.IdentityWithLowerDiagonal'>\n",
                        "D type: <class 'block_partitioned_matrices.Diagonal'>\n",
                        "U type: <class 'block_partitioned_matrices.IdentityWithUpperDiagonal'>\n",
                        "\n",
                        "Difference between tri @ v and L @ D @ U @ v:\n",
                        "0.0\n"
                    ]
                }
            ],
            "source": [
                "# Create a Tridiagonal Matrix\n",
                "tri = Tridiagonal(\n",
                "    [torch.eye(2) * 2, torch.eye(2) * 2, torch.eye(2) * 2],\n",
                "    lower_blocks=[0.5 * torch.ones(2, 2), 0.5 * torch.ones(2, 2)],\n",
                "    upper_blocks=[0.5 * torch.ones(2, 2), 0.5 * torch.ones(2, 2)],\n",
                ")\n",
                "print(\"Tridiagonal Matrix:\")\n",
                "print(tri.to_tensor())\n",
                "\n",
                "# Perform LDU Decomposition\n",
                "L, D, U = tri.LDU_decomposition()\n",
                "\n",
                "print(\"\\nDecomposed components:\")\n",
                "print(f\"L type: {type(L)}\")\n",
                "print(f\"D type: {type(D)}\")\n",
                "print(f\"U type: {type(U)}\")\n",
                "\n",
                "# Verify correctness by applying to a vector\n",
                "v = Vertical([col(1.0, 1.0), col(2.0, 2.0), col(3.0, 3.0)])\n",
                "\n",
                "# Apply original matrix\n",
                "tri_v = tri @ v\n",
                "\n",
                "# Apply decomposed factors: L @ (D @ (U @ v))\n",
                "LDU_v = L @ (D @ (U @ v))\n",
                "\n",
                "print(\"\\nDifference between tri @ v and L @ D @ U @ v:\")\n",
                "print((LDU_v - tri_v).to_tensor().norm().item())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
